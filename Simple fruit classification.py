# -*- coding: utf-8 -*-
"""Python_project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u6Izx8Pvua3YhwH2_FbOFnTAqIKfKOSk
"""

#import library
import pandas as pd    
import matplotlib.pyplot as plt    
import seaborn as sns   
import time 
import numpy as np
from sklearn.metrics import accuracy_score

# read csv file
df = pd.read_excel('/content/fruits.xlsx')

#view some of the data
df.head()

# check for any null values  
df.isnull().sum()

#fruits shape    
print(df.shape)

column_values = df[['fruit_label', 'fruit_name']].values.ravel()
unique_values =  pd.unique(column_values)
unique_values

print(df.groupby('fruit_name').size())

fruits = df[['mass','width','height', 'color_score', 'fruit_label']]
# set countplot palette
ax =sns.countplot(x = 'fruit_label', data=fruits)

# show count (+ annotate)
for rect in ax.patches:
    ax.text (rect.get_x() + rect.get_width()  / 2,rect.get_height()+ 0.75,rect.get_height(),horizontalalignment='center', fontsize = 11)

# plot values for each attribute
fruits[['mass', 'width', 'height', 'color_score']].plot()

# describe the data 
fruits.describe()

#preview data    
print(fruits.head())

# separate the data into train and test set
feature_names = ['mass', 'width', 'height', 'color_score']
X = fruits[feature_names]
y = fruits['fruit_label']

# Split the data
from sklearn.model_selection import train_test_split    
test_size = 0.3
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)

performance = []
# scale data
from sklearn.preprocessing import MinMaxScaler    
scaler = MinMaxScaler()    
X_train = scaler.fit_transform(X_train)    
X_test = scaler.transform(X_test)

#preview data after scalling 
transformed = pd.DataFrame(X_train)
print(transformed.head())

# plot values for each attribute after scaling
transformed.plot()

"""#DECISION TREE"""

# DecisionTreeClassifier    
from sklearn.tree import DecisionTreeClassifier   
# start with a timer
start_time = time.time()
# fit model
clf = DecisionTreeClassifier().fit(X_train, y_train)  
time_taken = time.time() - start_time
performance.append(('Decsision Tree', time_taken))
# predict values
y_predd = clf.predict(X_test)

# Accuracy
clf_train_score = clf.score(X_train, y_train)*100
clf_test_score = clf.score(X_test, y_test)*100

# Display performance
print('DecisionTreeClassifier:')    
print('Accuracy of training set: {:.2f} %'    
     .format(clf_train_score))    
print('Accuracy of test set: {:.2f} %'    
     .format(clf_test_score))  

# confusion matrix
print("\nConfusion Matrix")
confusion_matrix = pd.crosstab(y_test, y_predd, rownames=['Actual'], colnames=['Predicted'], margins = True)
print (confusion_matrix)

# adjust the font size 
plt.rcParams['font.size'] = 12
# histogram of predicted frequency
plt.hist(y_predd)

# x-axis limit from 0 to 1
plt.xlim(0,5)
plt.title('Predicted Frequency for Decision Tree')
plt.xlabel('Fruit Label')
plt.ylabel('Frequency')

#display the feature based on it importances
importancesdt = clf.feature_importances_
indicesdt = np.argsort(importancesdt)
feat_importancesdt = pd.Series(importancesdt, index=X.columns)
print('Feature Importance For Decision Tree')
print(feat_importancesdt)

#plot the graph based on importance features
plt.title('Feature Importance')
plt.barh(range(len(indicesdt)), importancesdt[indicesdt], align='center')
plt.yticks(range(len(indicesdt)), [feature_names[i] for i in indicesdt])
plt.xlabel('Relative Importance')
plt.show()

# install the package for decision tree
!pip install dtreeviz

import matplotlib.font_manager
from dtreeviz.trees import dtreeviz 

viz = dtreeviz(clf, X, y,
                target_name="target",
                feature_names=feature_names,
                class_names=['apple','mandarin','orange','lemon'])

viz

"""#LOGISTIC REGRESSION"""

#LogisticRegression    
from sklearn.linear_model import LogisticRegression    
# timer
start_time = time.time()
# fit model
logreg = LogisticRegression().fit(X_train, y_train) 
time_taken = time.time() - start_time
performance.append(('Logistic Regression', time_taken))
# predict values
y_predl = logreg.predict(X_test) 

# Accuracy
logreg_train_score = logreg.score(X_train, y_train)*100
logreg_test_score = logreg.score(X_test, y_test)*100

# Display performance
print('LogisticRegression:')    
print('Accuracy of training set: {:.2f} %'    
     .format(logreg_train_score))    
print('Accuracy of test set: {:.2f} %'    
     .format(logreg_test_score))  

# confusion matrix
print("\nConfusion Matrix")
confusion_matrix = pd.crosstab(y_test, y_predl, rownames=['Actual'], colnames=['Predicted'], margins = True)
print (confusion_matrix)

#plot the predicted value into a graph
# adjust the font size 
plt.rcParams['font.size'] = 12
# histogram of predicted frequency
plt.hist(y_predl)

# x-axis limit from 0 to 1
plt.xlim(0,5)
plt.title('Predicted frequency for Logistic Regression')
plt.xlabel('Fruit Label')
plt.ylabel('Frequency')

#display the feature based on it importances
importanceslg = logreg.coef_[0]
indiceslg = np.argsort(importanceslg)
feat_importanceslg = pd.Series(importanceslg, index=X.columns)
print('Feature Importance For Logistic Regression')
print(feat_importanceslg)

#plot the graph based on importance features
plt.title('Feature Importance For Logistic Regression')
plt.barh(range(len(indiceslg)), importanceslg[indiceslg], align='center')
plt.yticks(range(len(indiceslg)), [feature_names[i] for i in indiceslg])
plt.xlabel('Relative Importance')
plt.show()

"""#NAIVE BAYES"""

#GaussianNB    
from sklearn.naive_bayes import GaussianNB    
# timer
start_time = time.time()
# fit model
gnb = GaussianNB().fit(X_train, y_train)
time_taken = time.time() - start_time
performance.append(('Naive Bayes', time_taken))
# predict values
y_predb = gnb.predict(X_test) 

# Accuracy
gnb_train_score = gnb.score(X_train, y_train)*100
gnb_test_score = gnb.score(X_test, y_test)*100

# Display performance
print('GaussianNB:')    
print('Accuracy of training set: {:.2f} %'    
     .format(gnb_train_score))    
print('Accuracy of test set: {:.2f} %'    
     .format(gnb_test_score))  

# confusion matrix
print("\nConfusion Matrix")
confusion_matrix = pd.crosstab(y_test, y_predb, rownames=['Actual'], colnames=['Predicted'], margins = True)
print(confusion_matrix)

# adjust the font size 
plt.rcParams['font.size'] = 12
# histogram of predicted frequency
plt.hist(y_predb)

# x-axis limit from 0 to 1
plt.xlim(0,5)
plt.title('Predicted frequency for Naive Bayes')
plt.xlabel('Fruit Label')
plt.ylabel('Frequency')

#display the feature based on it importances
from sklearn.inspection import permutation_importance

imps = permutation_importance(gnb, X_test, y_test)
importancesnb = imps.importances_mean
indicesnb = np.argsort(importancesnb)
feat_importancesnb = pd.Series(importancesnb, index=X.columns)
print('Feature Importance For Naive Bayes')
print(feat_importancesnb)

#plot the graph based on importance features
plt.title('Feature Importance')
plt.barh(range(len(indicesnb)), importancesnb[indicesnb], align='center')
plt.yticks(range(len(indicesnb)), [feature_names[i] for i in indicesnb])
plt.xlabel('Relative Importance')
plt.show()

# All train scores
train_scores = []
train_scores.append(('Decision Tree', clf_train_score))
train_scores.append(('Logistic Regression', logreg_train_score))
train_scores.append(('Naive Bayes', gnb_train_score))
scores = pd.DataFrame(train_scores, columns =['Model', 'Train Score'])

# All test scores
test_scores = []
test_scores.append(('Decision Tree', clf_test_score))
test_scores.append(('Logistic Regression', logreg_test_score))
test_scores.append(('Naive Bayes', gnb_test_score))
t_scores = pd.DataFrame(test_scores, columns =['Model', 'Test Score'])

scores['Test Score'] = t_scores['Test Score']
scores

# compare algorithms
scores.plot.bar()

# plot time performance
time_performance = pd.DataFrame(performance, columns = ['Model', 'Time Taken'])
time_performance.plot.bar()